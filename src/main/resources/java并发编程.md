## java并发编程
- java并发编程的艺术
  - 1:并发真的快吗？
  > 不一定：并发会有线程的创建和上下文切换的开销
  > 从保存上下文到再加载的过程称为一次上下文切换
  - 2:如何减少上下文切换
  > 1:无锁并发编程 2：cas算法 3：使用最少线程 4：使用协程
    ```
    1:无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一
    些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。 
    2:CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁
    3:使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这
      样会造成大量线程都处于等待状态
    4:协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换
    ```  
  - 3:死锁
  > 相乘双发互相等待对方释放锁
    ```
    避免死锁的常见的几个方法
    1：避免一个线程同时获取多个锁
    2：避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源
    3：尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制
    4：对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况
    ```
  - 4:synchronized
  > java中的每个对象都可以作为锁，具体表现为一下三个形式
    ```
    1:对于普通同步方法，锁是当前实例对象
    2:对于静态同步方法，锁是当前的class对象
    3:对于同步方法块，锁是synchronized括号内配置的对象 
    ```
    > 当一个线程试图访问同步代码块时，他必须先获得锁，推出或抛出异常时必须释放锁
  - 5:锁的优缺点
    ```
    1:偏向锁：加锁和解锁不需要额外的消耗，和执行非同步方法相比仅存在纳秒级别的差距
            如果线程间存在锁竞争，会带来额外的锁撤销的消耗
            适用于只有一个线程访问同步块的场景
    2:轻量级锁:竞争的线程不会阻塞，提高了程序的响应速度
            如果始终得不到锁竞争的线程，使用自旋会消耗cpu
            追求响应时间，同步块执行速度非常快
    3:重量级锁:线程竞争不使用自旋，不消耗cpu
            线程阻塞，响应时间缓慢
            追求吞吐量，同步块执行时间较长
    ```
  - 6:cas实现原子操作的三大问题
    ```
    1:ABA问题：解决思路：加上版本号：1A-2B-3A:AtomicStampedReference
    2:循环时间长，开销大,自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销
    3:只能保证一个共享变量的原子操作;使用锁 或者 把多个共享变量合并成一个共享变量来
      操作。比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java 1.5开始，
      JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对
      象里来进行CAS操作。
          锁机制实现原子操作：偏向锁，轻量级锁，互斥锁，jvm中除了偏向锁，其他锁都是用了循环cas
          即当一个线程想进入同步块时使用循环cas的方式来获取锁，推出同步块时使用循环cas释放锁
    ```
  - 7:并发编程模型的两个关键问题
  > 线程之间如何通信以及线程之间如何同步
    - 在命令式编程中，线程通信机制分为：共享内存与消息传递
    - 同步：在共享内存并发模型中为显式，消息传递并发模型中为隐式

  - 8:java内存模型的抽象结构
  > 在Java中，所有实例域，静态域和数组元素都存储在堆内存中，堆内存在线程间共享，局部变量
  > 方法定义参数和异常处理参数不会在线程间共享，不会存在内存可见性问题
  
  - 9：JMM:JAVA内存模型
  > 线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了
  > 该线程以读写共享变量的副本，本地内存时JMM的一个抽象概念，并不真实存在，他涵盖了缓存，
  > 写缓冲区、寄存器以及其他硬件和编译器的优化
  
  - 10：线程之间的通信
  > JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证
  
  - 11：从源代码到指令序列的重排序
  > 在执行程序时，为了提高新能，编译器和处理器常常会对指令做重排序，分为以下3类
  ```
  1:编译器优化的重排序
    编译器在不改变单线程程序语义的前提下，可以重新安排语句
    的执行顺序
  2:指令级并行的重排序
    现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应
    机器指令的执行顺序
  3:内存系统的重排序
    由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上
    去可能是在乱序执行
  从源代码到最终执行的指令序列，会经历下面的重排序
    源代码--》编译器优化重排序--》指令集并行重排序--》内存系统重排序--》最终执行的指令序列
            编译器重排序       处理器重排序
  ```
  
  - 12:happens-before
  > JDK5开始，java使用JSR-133内存模型，其使用happens-before来阐述操作之间的可见性
  > 在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作必须存在happens-before关系
  ```
    1:程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作
    2:监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁
    3:volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读
    4:传递性；A->happens-before->B  B->happens-before->C 则A->happens-before->C
    注意：两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行，它
    仅仅要求前一个操作的结果对后一个操作可见，并且前一个操作按顺序在后一个操作之前
  ```
  
  - 13:数据依赖性
  > 如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性
  > 例如：写后读，读后写，写后写
  
  - 14: as-if-serial
  > 不管怎么重排序（编译器和处理器为了提高效率），（单线程）程序的执行结果不能被改变，编译器，runtime,处理器
  > 必须遵循该语义，所以编译器处理器不会对粗壮乃数据依赖的操作做重排序，反之，这些操作就有可能被重排序

  - 15:顺序一致性
  > 顺序一致性内存模型是一个理论参考模型，在设计的时候，处理器和编程语言的内存模型都会以此作为参考
  
  - 16:数据竞争与顺序一致性
  > 程序未正确同步时，就可能会存在数据竞争，JMM对数据竞争的定义如下：
  ```
    1:在一个线程中写一个变量
    2:在另一个线程中读同一个变量
    3:读和写没有通过同步来排序
    如果一个多线程程序能正确同步，僵尸一个没有竞争的程序
  ```
  > JMM对正确同步的多线程程序的内存一致性做了如下保证：如果程序是正确同步的，程序的执行将具有顺序一致性，
  > 即程序的执行结果与该程序的顺序一致性内存模型中的执行结果相同
  
  - 17:顺序一致性内存模型
  > 是一个理想化的计算机模型，未程序提供了极强的内存可见性保证：1：一个线程中的所有操作必须按照程序的顺序来执行
  > 2：（不管程序是否同步）所有的线程都只能看到单一的操作执行顺序，在顺序一致性内存模型中，每个操作都必须原子执行且立即对所有线程可见
  
  - 18：JMM不保证顺序一致性内存模型
  > 在JMM中，未同步的程序不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致，比如，在当前线程把写过的数据缓存在本地
  内存中，在没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观
  察，会认为这个写操作根本没有被当前线程执行。只有当前线程把本地内存中写过的数据刷
  新到主内存之后，这个写操作才能对其他线程可见。在这种情况下，当前线程和其他线程看到
  的操作执行顺序将不一致。
  
  - 19:同步程序的顺序一致性结果
  > 对程序使用锁来同步，在锁之内的代码可以视情况重排序（无依赖性数据），程序的执行结果将与程序在顺序一致性模型中的
  执行结果相同，JMM在具体实现上的基本方针为：在不改变（正确同步的）程序执
  行结果的前提下，尽可能地为编译器和处理器的优化打开方便之门
  
  - 20:未同步程序的执行特性
  > 对于未同步或未正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的
  值，要么是之前某个线程写入的值，要么是默认值（0，Null，False），JMM保证线程读操作读取
  到的值不会无中生有（Out Of Thin Air）的冒出来。为了实现最小安全性，JVM在堆上分配对象
  时，首先会对内存空间进行清零，然后才会在上面分配对象（JVM内部会同步这两个操作）。因
  此，在已清零的内存空间（Pre-zeroed Memory）分配对象时，域的默认初始化已经完成了
  
  - 21:未同步程序在顺序一致性模型和JMM中的差异
  ```
    1:顺序一致性模型保证单线程内的操作会按照程序的顺序执行，但是JMM不会（可能存在重排现象）
    2:顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证
    3:JMM不保证对64位的long型和double型变量的写操作具有原子性，而顺序一致性模型保证对所有的内存读写具有原子性
        --数据通过总线在处理器和内存之间传递，这一系列步骤称为总线事务，总线仲裁处理机制可以把所有处理器对内存的访问以串行化的方式来执行。在任意时
        间点，最多只能有一个处理器可以访问内存。这个特性确保了单个总线事务之中的内存读/写
        操作具有原子性
  ```
  
  - 22: volatile
  > volatile变量自身具有可见性以及原子性，但是类似于volatile++这种复合操作不具备原子性
  > volatile的写-读内存语义；在写的收会将该线程中本地内存的共享变量刷新到主内存
  > 读：会将本地内存的共享变量置为无效，线程接下来将从主内存读取共享变量
  ```
    结合volatile写-读步骤一起来看的话，可以得出：在读一个volatile变量之后以及在写一个volatile变量之前的所有可见的共享变量的值都将内存可见
    1：当第一个操作是volatile读时，不管第二个操作是什么，都不能重排
    2：当第二个操作是volatile写时，不管第一个操作是什么，都不能重排
    3：当第一个操作是volatile写，第二个操作是volatile读，也不能重排
  ```
  
  - 23:JMM volatile内存屏障策略
  ```
  1:Load屏障：执行读取数据的时候，强制每次都从主内存读取最新的值
  2:Store屏障：每次执行修改数据的时候，强制刷新回主内存
  为了实现volatile内存语义，JMM采取保守策略：
    1：在每个volatile写操作的前面插入一个StoreStore屏障（禁止上面的普通写与下面的volatile写重排序）
    2：在每个volatile写操作的后面插入一个StoreLoad屏障（禁止上面的volatile写与下面的volatile读、写重排序）
         或者在每个volatile读的前面插入StoreLoad屏障
            从整体执行效率的角度考虑，JMM最终选择了在每个
            volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是：一个
            写线程写volatile变量，多个读线程读同一个volatile变量。当读线程的数量大大超过写线程时，
            选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升
    3：在每个volatile读操作的后面插入一个LoadLoad屏障（禁止上面的volatile读与下面的普通读重排序）
    4：在每个volatile读操作的后面插入一个LoadStore屏障（禁止上面的volatile读与下面的普通读、写重排序）
  所以：volatile的写-读和锁的释放-获取具有相同的内存语义

  ```
  > 由于volatile仅仅保证对单个volatile变量的读/写具有原子性，而锁的互斥执行的特性可以
  确保对整个临界区代码的执行具有原子性。在功能上，锁比volatile更强大；在可伸缩性和执行
  性能上，volatile更有优势。如果读者想在程序中用volatile代替锁，请一定谨慎，具体详情请参
  阅Brian Goetz的文章《Java理论与实践：正确使用Volatile变量》。

  - 24:锁的释放-获取建立的happens-before关系
  > 锁是java并发编程中最重要的同步机制，锁除了让临界区互斥之外，还可以让释放锁的线程向获取同一个锁的线程发送消息
  > 线程A在释放锁之前所有可见的共享变量，在线程B获取同一个锁之后，将立刻变得
  对B线程可见
  
  - 25:锁的释放和获取的内存语义
  > 当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中
  > 当线程获取锁时，JMM会把该线程对应的本地内存置为无效，
  > 从而使得被监视器保护的临界区代码必须从主内存中读取共享变量
  
  ```
    对比锁释放-获取的内存语义与volatile写-读的内存语义可以看出：
      锁释放与volatile写有相同的内存语义
      锁获取与volatile读有相同的内存语义
  总结：
    1:线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了（线程A
    对共享变量所做修改的）消息
    2:线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共
    享变量所做修改的）消息
    3:线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发
    送消息
  ```
    
  - 26:锁内存语义的实现
  > 借助ReentrantLock源码，分析锁内存语义的实现机制
  ```
    ReentrantLock的实现依赖于java同步器框架AbstractQueuedSynchronizer(AQS),
    AQS使用一个整型的volatile变量，名为state来维护同步状态
  ```
  - 27:公平锁
  > 公平锁在释放锁的最后写volatile变量state，在获取锁时首先读这个volatile变量。根据
  volatile的happens-before规则，释放锁的线程在写volatile变量之前可见的共享变量，在获取锁
  的线程读取同一个volatile变量后将立即变得对获取锁的线程可见
  - 28:非公平锁
  > 获取锁时调用的是：AbstractQueuedSynchronizer:compareAndSetState(int expect,int update)。
  > 该方法以原子操作的方式更新state变量：如果当前状态值等于预期值，则以原子方式将同步状态
  设置为给定的更新值。此操作具有volatile读和写的内存语义
  - why?(此操作(CAS)具有volatile读和写的内存语义)
  > 编译器不会对volatile读与volatile读后面的任意内存操作重排序；编译
  器不会对volatile写与volatile写前面的任意内存操作重排序。组合这两个条件，意味着为了同
  时实现volatile读和volatile写的内存语义，编译器不能对CAS与CAS前面和后面的任意内存操
  作重排序
  
  - 29:总结公平锁与非公平锁的内存语义
  ```
    1:公平锁和非公平锁释放时，最后都要写一个volatile变量state。
    2:公平锁获取时，首先会去读volatile变量。
    3:非公平锁获取时，首先会用CAS更新volatile变量，这个操作同时具有volatile读和volatile
      写的内存语义
    锁释放-获取的内存语义的实现至少有下面两种:
      1:利用volatile变量的写-读所具有的内存语义。(公平锁实现)
      2:利用CAS所附带的volatile读和volatile写的内存语义（非公平锁实现）
  ```
  - 30:concurrent包的实现
  ```
    由于java的cas同事具有volatile读，volatile写的内存语义，因此java线程间的通信有了以下四种方式
    1：A线程写volatile变量，随后B线程读这个volatile变量
    2：A线程写volatile变量，随后B线程用CAS更新这个volatile变量
    3：A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量
    4：A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量
    分析concurrent包的实现可以发下以下通用化实现模式：
    1：声明共享变量为volatile;
    2：使用cas的原子条件更新来实现线程之间同步
    3：配合以volatile的读、写和cas所具有的volatile读、写的内存语义实现线程间的通信
    AQS、非阻塞数据结构、原子变量类，这些concurrent包中的基础类都是使用这种模式实现的
    有低级到高级排列如下：
    volatile变量的读、写              CAS
    AQS     非阻塞数据结构        原子变量类
    Lock 同步器  阻塞队列  Executor 并发容器   
  ```
  - 31:final域的内存语义
  ```
  final域的重排序规则：
  1:在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用
    变量，这两个操作之间不能重排序
  2:初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能
    重排序
  写final域的重排序规则：
  写final域的重排序规则禁止把final域的写重排序到构造函数之外
  1：JMM禁止编译器把final域的写重排序到构造函数之外
  2：编译器会在final域写之后，构造函数return之前，插入一个storestore屏障，这个屏障禁止处理器把final域的写重排序到构造函数之外
  ```
  > 写final域的重排序规则可以确保：在对象引用为任意线程可见之前，对象final域已经被正确初始化过了，
  > 而普通域则不具备这个保障
  ```
  读final域的重排序规则：
  在一个线程中，初次读对象引用与初次读该对象包含的final
  域，JMM禁止处理器重排序这两个操作（注意，这个规则仅仅针对处理器）。编译器会在读final
  域操作的前面插入一个LoadLoad屏障
  读final域的重排序规则可以确保：
  在读一个对象的final域之前，一定会先读包含这个final
  域的对象的引用。在这个示例程序中，如果该引用不为null，那么引用对象的final域一定已经
  被A线程初始化过了
  ```
  - 32:final域为引用类型
  > 在构造函数内对一个final引用的对象的成员域
  的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之
  间不能重排序

  ```
  在构造函数返回前，被构造对象的引用不能为其他线程所见，因为此
  时的final域可能还没有被初始化。在构造函数返回后，任意线程都将保证能看到final域正确初
  始化之后的值
  ```
  - 33:JSR-133为什么要增强final语义
  >在旧的Java内存模型中，一个最严重的缺陷就是线程可能看到final域的值会改变。比如，
  一个线程当前看到一个整型final域的值为0（还未初始化之前的默认值），过一段时间之后这个
  线程再去读这个final域的值时，却发现值变为1（被某个线程初始化之后的值）。最常见的例子
  就是在旧的Java内存模型中，String的值可能会改变。
  为了修补这个漏洞，JSR-133专家组增强了final的语义。通过为final域增加写和读重排序
  规则，可以为Java程序员提供初始化安全保证：只要对象是正确构造的（被构造对象的引用在
  构造函数中没有“逸出”），那么不需要使用同步（指lock和volatile的使用）就可以保证任意线程
  都能看到这个final域在构造函数中被初始化之后的值
  
  - 34:happens-before
  > 《JSR-133:Java Memory Model and Thread Specification》对happens-before关系的定义如下。
  1）如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作
  可见，而且第一个操作的执行顺序排在第二个操作之前。
  2）两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照
  happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系
  来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）。
  上面的1）是JMM对程序员的承诺。从程序员的角度来说，可以这样理解happens-before关
  系：如果A happens-before B，那么Java内存模型将向程序员保证——A操作的结果将对B可见，
  且A的执行顺序排在B之前。注意，这只是Java内存模型向程序员做出的保证！
  上面的2）是JMM对编译器和处理器重排序的约束原则。正如前面所言，JMM其实是在遵
  循一个基本原则：只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），
  编译器和处理器怎么优化都行。JMM这么做的原因是：程序员对于这两个操作是否真的被重
  排序并不关心，程序员关心的是程序执行时的语义不能被改变（即执行结果不能被改变）。因
  此，happens-before关系本质上和as-if-serial语义是一回事。
  ·as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同
  步的多线程程序的执行结果不被改变。
  ·as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺
  序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正
  确同步的多线程程序是按happens-before指定的顺序来执行的。
  as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提
  下，尽可能地提高程序执行的并行度。
  
  - 35:happens-before
  ```
  《JSR-133:Java Memory Model and Thread Specification》定义了如下happens-before规则。
   1）程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
   2）监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
   3）volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的
     读。
   4）传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。
   5）start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的
     ThreadB.start()操作happens-before于线程B中的任意操作。
     --线程A在执行ThreadB.start()之前对共享
     变量所做的修改，接下来在线程B开始执行后都将确保对线程B可见
   6）join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作
     happens-before于线程A从ThreadB.join()操作成功返回
     --假设线程A在执行的过程中，通过执行ThreadB.join()来等待线
     程B终止；同时，假设线程B在终止之前修改了一些共享变量，线程A从ThreadB.join()返回后会
     读这些共享变量
  ```
  - 36:双重检查锁定与延迟初始化
  > 在Java多线程程序中，有时候需要采用延迟初始化来降低初始化类和创建对象的开销。双
  重检查锁定是常见的延迟初始化技术，但它是一个错误的用法。我们将分析双重检查锁定的
  错误根源，以及两种线程安全的延迟初始化方案
  
  - 37: java程序的内存可见性保证
  ```
  单线程程序。单线程程序不会出现内存可见性问题。编译器、runtime和处理器会共同确
    保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。
  正确同步的多线程程序。正确同步的多线程程序的执行将具有顺序一致性（程序的执行
    结果与该程序在顺序一致性内存模型中的执行结果相同）。这是JMM关注的重点，JMM通过限
    制编译器和处理器的重排序来为程序员提供内存可见性保证。
  未同步/未正确同步的多线程程序。JMM为它们提供了最小安全性保障：线程执行时读取
    到的值，要么是之前某个线程写入的值，要么是默认值（0、null、false）
  ```
  - 38 JSR-133对旧内存模型的修补
  ```
  ·增强volatile的内存语义。旧内存模型允许volatile变量与普通变量重排序。JSR-133严格
   限制volatile变量与普通变量的重排序，使volatile的写-读和锁的释放-获取具有相同的内存语
   义。
  ·增强final的内存语义。在旧内存模型中，多次读取同一个final变量的值可能会不相同。为
   此，JSR-133为final增加了两个重排序规则。在保证final引用不会从构造函数内逸出的情况下，
   final具有了初始化安全性 
  ```
  - java并发编程基础
  - 39:是什么时线程
  > 






- java并发编程实践